{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_n_estimator(x_train, y_train, x_test, y_test):\n",
    "        error_rate = []\n",
    "        # Will take some time\n",
    "        k_values = list(filter(lambda x: x % 2 == 1, range(0, 50)))\n",
    "        for i in k_values:\n",
    "            knn = KNeighborsClassifier(n_neighbors=i)\n",
    "            knn.fit(x_train, y_train)\n",
    "            pred_i = knn.predict(x_test)\n",
    "            error_rate.append(np.mean(pred_i != y_test))\n",
    "        best_k_index = error_rate.index(np.min(error_rate))\n",
    "        best_n_estimator = best_k_index * 2 + 1\n",
    "\n",
    "        return best_n_estimator\n",
    "\n",
    "def KNNClassifier(x_train, y_train, x_test, y_test):\n",
    "    best_n = best_n_estimator(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    knn_classifier = KNeighborsClassifier(\n",
    "        n_neighbors= best_n)\n",
    "    knn_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# picking models for prediction.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ensemble models for better performance\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "#from MiscellaneousFunctions import display_classification_report\n",
    "\n",
    "class BivariateClassification():\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.logistic_regression = LogisticRegression()\n",
    "        self.support_vector_machine = SVC()\n",
    "        self.decision_tree_classifier = DecisionTreeClassifier()\n",
    "        self.random_forest_classifier = RandomForestClassifier()\n",
    "        self.adaboost_classifer = AdaBoostClassifier()\n",
    "\n",
    "        self.all_models = [self.logistic_regression, self.support_vector_machine, self.decision_tree_classifier, \n",
    "                           self.random_forest_classifier, self.adaboost_classifer]\n",
    "        self.all_model_names = ['Logistic Regression', 'Support Vector Classifier', 'Decision Tree Classifier', \n",
    "                           'Random Forest Classifier', 'Adaboost Classifier']\n",
    "\n",
    "        self.metric_names = ['Accuracy Score', 'Confusion Matrix',\n",
    "                            'F1 Score']\n",
    "\n",
    "        self.train_scores = []\n",
    "        self.test_scores = []        \n",
    "        self.metric_list = [accuracy_score, confusion_matrix, f1_score]\n",
    "        self.metrics = []\n",
    "        data = {'Model Names': self.all_model_names}\n",
    "        self.all_model_info = pd.DataFrame(data)\n",
    "    \n",
    "    def fit(self, x_train, x_test, y_train, y_test):\n",
    "        '''\n",
    "        fits models to data and stores results for metrics\n",
    "        '''\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "        for model in self.all_models:\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "        self.apply_metrics()\n",
    "\n",
    "    def apply_metrics(self):\n",
    "        self.metrics = []\n",
    "        for metric in self.metric_list:\n",
    "            metric_name = str(metric).split(' ')[1]\n",
    "            for model in self.all_models:\n",
    "                metric_item = metric(self.y_test, model.predict(self.x_test))\n",
    "                self.metrics.append(metric_item)\n",
    "                \n",
    "            self.all_model_info[metric_name] = self.metrics\n",
    "            self.metrics = []\n",
    "\n",
    "    def display_report(self):\n",
    "        display_classification_report(self.all_model_names, self.all_models, self.y_test, self.x_test)\n",
    "        return self.all_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1   col2   col3   col4   target\n",
       "0     5      5      5      5        1\n",
       "1     4      4      4      4        0\n",
       "2     6      6      6      6        1\n",
       "3     3      3      3      3        0\n",
       "4     5     10     15     20        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 4) (12,) (3, 4) (3,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features = df.iloc[:, 0:4]\n",
    "target = df.iloc[:, -1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42) \n",
    "#random state so our data doesnt change\n",
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclassifier = BivariateClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclassifier.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclassifier.apply_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_classification_report(all_model_names, all_models, y_test, x_test):\n",
    "    for name, model in zip(all_model_names, all_models):\n",
    "            metric_item = classification_report(y_test, model.predict(x_test))\n",
    "            print(name)\n",
    "            print(metric_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.50      0.33      0.40         3\n",
      "weighted avg       1.00      0.67      0.80         3\n",
      "\n",
      "Support Vector Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.50      0.17      0.25         3\n",
      "weighted avg       1.00      0.33      0.50         3\n",
      "\n",
      "Decision Tree Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.50      0.17      0.25         3\n",
      "weighted avg       1.00      0.33      0.50         3\n",
      "\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.50      0.17      0.25         3\n",
      "weighted avg       1.00      0.33      0.50         3\n",
      "\n",
      "Adaboost Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.50      0.17      0.25         3\n",
      "weighted avg       1.00      0.33      0.50         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Names</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[[0, 0], [1, 2]]</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[[0, 0], [2, 1]]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[[0, 0], [2, 1]]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[[0, 0], [2, 1]]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost Classifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[[0, 0], [2, 1]]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Names  accuracy_score  confusion_matrix  f1_score\n",
       "0        Logistic Regression        0.666667  [[0, 0], [1, 2]]       0.8\n",
       "1  Support Vector Classifier        0.333333  [[0, 0], [2, 1]]       0.5\n",
       "2   Decision Tree Classifier        0.333333  [[0, 0], [2, 1]]       0.5\n",
       "3   Random Forest Classifier        0.333333  [[0, 0], [2, 1]]       0.5\n",
       "4        Adaboost Classifier        0.333333  [[0, 0], [2, 1]]       0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclassifier.display_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
